{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "data = pd.read_csv(\"pvq21CENTRED.csv\", sep=',')\n",
    "lib_dataframe = data.copy()\n",
    "con_dataframe = data.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin the data for each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_lib (value):\n",
    "\n",
    "        if value < 3:\n",
    "            return \"liberal\" #liberal\n",
    "        else:\n",
    "            return \"moderate\" #moderate\n",
    "\n",
    "def normalise_con (value):\n",
    "        \n",
    "        if value > 6:\n",
    "            return \"conservative\" #conservative\n",
    "        else:\n",
    "            return \"moderate\" #moderate\n",
    "        \n",
    "\n",
    "lib_dataframe['lrscale'] = lib_dataframe['lrscale'].apply(normalise_lib)\n",
    "con_dataframe['lrscale'] = con_dataframe['lrscale'].apply(normalise_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lib = lib_dataframe.iloc[:, 2:12].copy()\n",
    "y_lib = lib_dataframe.iloc[:,1].copy()\n",
    "#Now the data frame for conservative prediction\n",
    "X_con = con_dataframe.iloc[:, 2:12].copy()\n",
    "y_con = con_dataframe.iloc[:,1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9391"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_con).count(\"conservative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_onehot = label_encoder.fit_transform(y_lib.copy())\n",
    "y_con_onehot = label_encoder.fit_transform(y_con.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_oh, X_test_lib_oh, y_train_lib_oh, y_test_lib_oh = train_test_split(X_lib, y_lib_onehot, test_size=0.25, random_state=10)\n",
    "X_train_con_oh, X_test_con_oh, y_train_con_oh, y_test_con_oh = train_test_split(X_con, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function to perform cross validation to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(model):\n",
    "    #return scores\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class Lasso():\n",
    "lasso_LIB_model = Lasso(alpha=1.0)\n",
    "#fitting the liberal model\n",
    "lasso_LIB_model.fit(X_train_lib_oh,y_train_lib_oh)\n",
    "\n",
    "lasso_CON_model = Lasso(alpha=1.0)\n",
    "lasso_CON_model.fit(X_train_con_oh,y_train_con_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96219289 0.96219289 0.96219289 ... 0.96219289 0.96219289 0.96219289]\n",
      "The ground truth labels:\n",
      "Liberal LASSO accuracy: \n",
      "[ 0. -0.  0.  0.  0.  0. -0. -0. -0. -0.]\n",
      "\n",
      "[0.93714705 0.93714705 0.93714705 ... 0.93714705 0.93714705 0.93714705]\n",
      "The ground truth labels:\n",
      "[1 1 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "lasso_lib_pred = lasso_LIB_model.predict(X_test_lib_oh)\n",
    "print(lasso_lib_pred)\n",
    "\n",
    "#enc.inverse_transform([np.argmax(lasso_lib_pred[0, :])])\n",
    "#print(lasso_lib_pred[0, :])\n",
    "print(\"The ground truth labels:\")\n",
    "#print(np.argmax(y_test_lib_oh, axis = 1))\n",
    "print(\"Liberal LASSO accuracy: \")\n",
    "#print(accuracy_score(y_test_lib_oh, lasso_lib_pred))#np.argmax(y_test_lib_oh, axis = 1), np.argmax(lasso_LIB_model.predict(X_test_lib_oh), axis=1)))\n",
    "print(lasso_LIB_model.coef_) #feature significance\n",
    "print()\n",
    "print(lasso_CON_model.predict(X_test_con_oh))\n",
    "print(\"The ground truth labels:\")\n",
    "print(y_test_con_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP: One hot encoding does not work well with Logistic Regression; a one hot encoding will case the matrix of input data to become singular, meaning it cannot be inverted and the linear regression coefficients cannot be calculated using linear algebra. For these types of models a dummy variable encoding must be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: Label encoding the data for the Logistic Regression (and the Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lib_cat = y_lib.copy()        #NOT SURE WHAT THIS STEP DOES, MAYBE IT IS REDUNDANT\n",
    "y_con_cat = y_con.copy()\n",
    "\n",
    "y_lib_cat = y_lib_cat.astype('category')\n",
    "y_con_cat = y_con_cat.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib_cat)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_l, X_test_lib_l, y_train_lib_l, y_test_lib_l = train_test_split(X_lib, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con_l, X_test_con_l, y_train_con_l, y_test_con_l = train_test_split(X_con, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_LIB = LogisticRegression(random_state=0)\n",
    "logistic_regression_LIB.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "logistic_regression_CON = LogisticRegression(random_state=0)\n",
    "logistic_regression_CON.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lrscale</th>\n",
       "      <th>universalism</th>\n",
       "      <th>achievement</th>\n",
       "      <th>benevolence</th>\n",
       "      <th>self_direction</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>hedonism</th>\n",
       "      <th>power</th>\n",
       "      <th>security</th>\n",
       "      <th>conformity</th>\n",
       "      <th>tradition</th>\n",
       "      <th>p_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  lrscale  universalism  achievement  benevolence  \\\n",
       "0           0        0           1.5          2.5          1.5   \n",
       "\n",
       "   self_direction  stimulation  hedonism  power  security  conformity  \\\n",
       "0             3.0          3.5       4.0    4.0       4.5         6.0   \n",
       "\n",
       "   tradition  p_avg  \n",
       "0        4.5    3.5  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal LR predicts:  [1 1 1 ... 1 1 1]\n",
      "Ground truth:  [0 1 1 ... 1 1 1]\n",
      "0.8820682068206821\n",
      "Conservative LR predicts: \n",
      "Ground truth:  [1 1 1 ... 1 0 1]\n",
      "0.8481848184818482\n",
      "\n",
      "LIBERAL COEFFICIENTS\n",
      "[[ 0.64696149  0.10334159  0.00508842  0.03620765 -0.00407959  0.05359682\n",
      "  -0.02097152 -0.05334792 -0.013917   -0.057601  ]]\n",
      "\n",
      "CONSERVATIVE COEFFICIENTS\n",
      "[[-0.39614516  0.027852    0.03136662  0.11140505  0.06367177 -0.00044922\n",
      "   0.11708522  0.08849489  0.14891201  0.24233131]]\n"
     ]
    }
   ],
   "source": [
    "LR_lib_pred = logistic_regression_LIB.predict(X_test_lib_l)\n",
    "print(\"Liberal LR predicts: \",LR_lib_pred )\n",
    "print(\"Ground truth: \", y_test_lib_l)\n",
    "\n",
    "print(accuracy_score(y_test_lib_l, LR_lib_pred))\n",
    "\n",
    "LR_con_pred = logistic_regression_CON.predict(X_test_con_l)\n",
    "print(\"Conservative LR predicts: \", )\n",
    "print(\"Ground truth: \", y_test_con_l)\n",
    "print(accuracy_score(y_test_con_l, LR_con_pred))\n",
    "print()\n",
    "print(\"LIBERAL COEFFICIENTS\")\n",
    "print(logistic_regression_LIB.coef_)\n",
    "\n",
    "print()\n",
    "print(\"CONSERVATIVE COEFFICIENTS\")\n",
    "print(logistic_regression_CON.coef_)\n",
    "\n",
    "# Liberal LR predicts:  [0 0 0 ... 0 0 0]\n",
    "# Ground truth:  [1 0 0 ... 0 0 0]\n",
    "# 0.8820682068206821\n",
    "# Conservative LR predicts: \n",
    "# Ground truth:  [0 0 0 ... 0 1 0]\n",
    "# 0.7358635863586359"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result interpretation:\n",
    "\n",
    "LIBERAL COEFFICIENTS\n",
    "[[ 0.64696149  0.10334159  0.00508842  0.03620765 -0.00407959  0.05359682\n",
    "  -0.02097152 -0.05334792 -0.013917   -0.057601  ]]\n",
    "\n",
    "CONSERVATIVE COEFFICIENTS\n",
    "[[-0.39614516  0.027852    0.03136662  0.11140505  0.06367177 -0.00044922\n",
    "   0.11708522  0.08849489  0.14891201  0.24233131]]\n",
    "   \n",
    "The external correlations match those given at https://gosling.psy.utexas.edu/wp-content/uploads/2016/12/Sandy-et-al-JPA-2016-Brief-values-measures.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix: \n",
    "Shows that the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[   0 1072]\n",
      " [   0 8018]]\n",
      "conservative confusion matrix: \n",
      " [[   0 1380]\n",
      " [   0 7710]]\n"
     ]
    }
   ],
   "source": [
    "cm_lib = metrics.confusion_matrix(y_test_lib_l, LR_lib_pred)\n",
    "print(\"liberal confusion matrix: \\n\", cm_lib)\n",
    "\n",
    "cm_con = metrics.confusion_matrix(y_test_con_l, LR_con_pred)\n",
    "print(\"conservative confusion matrix: \\n\", cm_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88476348 0.88476348 0.88476348 0.88476348 0.88476348 0.88476348\n",
      " 0.88476348 0.88476348 0.8850385  0.8850385 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_LIB_CVVVVV = LogisticRegression(random_state=0)\n",
    "\n",
    "cv_results_lib = cross_validate(logistic_regression_LIB_CVVVVV, X_lib, y_lib_labelencoded, cv=10)\n",
    "\n",
    "cv_results_con = cross_validate(logistic_regression_CON, X_con, y_con_labelencoded, cv=3)\n",
    "\n",
    "print(cv_results_lib['test_score'])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "… there are occasions when a complete set of dummy variables is useful. For example, the splits in a tree-based model are more interpretable when the dummy variables encode all the information for that predictor. We recommend using the full set if dummy variables when working with tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of liberal Random Forest  0.8797579757975797\n",
      "Accuracy of conservative Random Forest  0.8467546754675468\n"
     ]
    }
   ],
   "source": [
    "rf_lib = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "rf_lib.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "rf_con = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_lib.fit(X_train_con_l, y_train_con_l)\n",
    "\n",
    "\n",
    "rf_lib_predicted = rf_lib.predict(X_test_lib_l)\n",
    "rf_con_predicted = rf_lib.predict(X_test_con_l)\n",
    "\n",
    "print(\"Accuracy of liberal Random Forest \", accuracy_score(y_test_lib_l,rf_lib_predicted))\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con_l,rf_con_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[   3 1069]\n",
      " [  24 7994]]\n",
      "conservative confusion matrix: \n",
      " [[   7 1373]\n",
      " [  20 7690]]\n"
     ]
    }
   ],
   "source": [
    "rf_cm_lib = metrics.confusion_matrix(y_test_lib_l, rf_lib_predicted)\n",
    "print(\"liberal confusion matrix: \\n\", rf_cm_lib)\n",
    "\n",
    "rf_cm_con = metrics.confusion_matrix(y_test_con_l, rf_con_predicted)\n",
    "print(\"conservative confusion matrix: \\n\", rf_cm_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_gnb = GaussianNB()\n",
    "\n",
    "lib_gnb.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "\n",
    "con_gnb = GaussianNB()\n",
    "\n",
    "con_gnb.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8729372937293729\n",
      "[[  82 1199]\n",
      " [ 187 9440]]\n",
      "82 1199 187 9440\n",
      "0.8504767143381005\n",
      "[[  10 1621]\n",
      " [  10 9267]]\n"
     ]
    }
   ],
   "source": [
    "lib_gnb_predicted = lib_gnb.predict(X_test_lib_l)\n",
    "gnb_cm_lib = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted,labels = )\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted).ravel()\n",
    "\n",
    "con_gnb_predicted = con_gnb.predict(X_test_con_l)\n",
    "gnb_cm_con = metrics.confusion_matrix(y_test_con_l,con_gnb_predicted)\n",
    "print(accuracy_score(y_test_lib_l,lib_gnb_predicted))\n",
    "print(gnb_cm_lib)\n",
    "print(tn, fp, fn, tp)\n",
    "print(accuracy_score(y_test_con_l,con_gnb_predicted))\n",
    "print(gnb_cm_con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - experiments: \n",
    "*first attempt on the conservative classifier*\n",
    "\n",
    "Liberal significant features: \n",
    "\n",
    "Conservative significant features: Conformity, Tradition, Universalism, Self direction, Stimulation, Hedonism, Achievement (power), Security\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>universalism</th>\n",
       "      <th>achievement</th>\n",
       "      <th>self_direction</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>hedonism</th>\n",
       "      <th>power</th>\n",
       "      <th>security</th>\n",
       "      <th>conformity</th>\n",
       "      <th>tradition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.50</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.20</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>4.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.35</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>2.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.40</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>3.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.55</td>\n",
       "      <td>4.383333</td>\n",
       "      <td>2.883333</td>\n",
       "      <td>4.883333</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>4.383333</td>\n",
       "      <td>4.383333</td>\n",
       "      <td>4.383333</td>\n",
       "      <td>3.383333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   universalism  achievement  self_direction  stimulation  hedonism     power  \\\n",
       "0          1.50     2.500000        3.000000     3.500000  4.000000  4.000000   \n",
       "1          2.20     2.866667        2.366667     3.866667  3.866667  3.866667   \n",
       "2          2.35     5.350000        2.850000     6.350000  2.850000  4.350000   \n",
       "3          3.40     3.566667        3.066667     4.066667  3.066667  3.566667   \n",
       "4          2.55     4.383333        2.883333     4.883333  1.883333  4.383333   \n",
       "\n",
       "   security  conformity  tradition  \n",
       "0  4.500000    6.000000   4.500000  \n",
       "1  4.366667    4.866667   4.366667  \n",
       "2  1.350000    4.350000   2.850000  \n",
       "3  3.066667    4.566667   3.066667  \n",
       "4  4.383333    4.383333   3.383333  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con_featureslected = X_con.copy().drop(['benevolence'], axis = 1)\n",
    "\n",
    "X_con_featureslected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_con_oh_fs, X_test_con_oh_fs, y_train_con_oh_fs, y_test_con_oh_fs = train_test_split(X_con_featureslected, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_con_gnb = GaussianNB()\n",
    "\n",
    "fs_con_gnb.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  605    4 8479]\n",
      "0.933003300330033\n",
      "['moderate' 'moderate' 'moderate' ... 'moderate' 'moderate' 'moderate']\n",
      "[[   2  605]\n",
      " [   4 8479]]\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "fs_con_gnb_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "fs_gnb_cm_con = metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted)\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted).ravel())\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(label_encoder.inverse_transform(fs_con_gnb_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(list(fs_con_gnb_predicted).count(0))\n",
    "print(list(label_encoder.inverse_transform(fs_con_gnb_predicted)).count('conservative'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "(with normalisations of conservatives over 7 (i.e. > 7)\n",
    "- NB using OneHot encoding and having removed Benevolence: 93% accuracy\n",
    "[   2  605]\n",
    " [   4 8479]]\n",
    " \n",
    "- NB using OneHot encoding and having removed Benevelonece & Power: 93% accuracy\n",
    "[[   0  607]\n",
    " [   2 8481]]\n",
    "\n",
    "-  NB using Label encoding and having removed Benevolence: 84.8% accuracy\n",
    "[[  10 1370]\n",
    " [   8 7702]]\n",
    " \n",
    "- NB using Label encoding and having removed Benevolence & Power: 84.8%\n",
    "[[   6 1374]\n",
    " [   3 7707]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_rf_con = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "fs_rf_con.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933003300330033\n",
      "[[   2  605]\n",
      " [   4 8479]]\n"
     ]
    }
   ],
   "source": [
    "fs_rf_con_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_rf_con_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_rf_con_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Algorithms\n",
    "\n",
    "- Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model purposes to rank, i.e. producing a permutation of items in new, unseen lists in a similar way to rankings in the training data.\n",
    "\n",
    "Ideas: \n",
    "    - Rank based on 'higher value = most important' (i.e. based on the assumption that conservatives have similar higher values  and similar lower values)\n",
    "    - Rank based  on ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lib_RANK1 = X_lib.copy()\n",
    "X_con_RANK1 = X_con.copy()\n",
    "\n",
    "# X_lib_RANK1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_value (dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df_comps = pd.DataFrame()\n",
    "    col_name =''\n",
    "    for column_name, data in df.iteritems():\n",
    "        for other_column_name, other_data in df.iteritems():\n",
    "            if column_name != other_column_name:\n",
    "                comp_col_name = column_name + ' < ' + other_column_name\n",
    "                df_comps[comp_col_name] = df[column_name] < df[other_column_name]\n",
    "\n",
    "    return df_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_con_RANK = relative_value(X_con_RANK1)\n",
    "X_lib_RANK = X_con_RANK.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_lib = lib_dataframe.iloc[:, 2:12].copy()\n",
    "# y_lib = lib_dataframe.iloc[:,1].copy()\n",
    "# #Now the data frame for conservative prediction\n",
    "# X_con = con_dataframe.iloc[:, 2:12].copy()\n",
    "# y_con = con_dataframe.iloc[:,1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib, X_test_lib, y_train_lib, y_test_lib = train_test_split(X_lib_RANK, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con, X_test_con, y_train_con, y_test_con = train_test_split(X_con_RANK, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test_con).count(\"conservative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_gnb_RANK = GaussianNB()\n",
    "con_gnb_RANK.fit(X_train_con, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6491565823248991\n",
      "[[ 932 1927]\n",
      " [1900 6149]]\n"
     ]
    }
   ],
   "source": [
    "con_RANK_predicted = con_gnb_RANK.predict(X_test_con)\n",
    "\n",
    "print(accuracy_score(y_test_con,con_RANK_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con,con_RANK_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_con_RANK = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_con_RANK.fit(X_train_con, y_train_con_l)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of conservative Random Forest  0.7326732673267327\n",
      "[[  45 2814]\n",
      " [ 102 7947]]\n",
      "tn 45 fp 2814 fn 102 tp 7947\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "rf_con_RANK_predicted = rf_con_RANK.predict(X_test_con)\n",
    "\n",
    "\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted).ravel()\n",
    "\n",
    "print(metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "# print(\"tn\",tn, \"fp\",fp, \"fn\",fn,\"tp\", tp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "['moderate' 'moderate' 'moderate' ... 'moderate' 'moderate' 'moderate']\n"
     ]
    }
   ],
   "source": [
    "print(rf_con_RANK_predicted)\n",
    "print(label_encoder.inverse_transform(rf_con_RANK_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "_Normalistion point @ 8_\n",
    "Accuracy of conservative Random Forest  0.9242757609094243\n",
    "\n",
    "Sensitivity = 0.9872486512996567\n",
    "Specificity = 0.023842917251051893\n",
    "\n",
    "[   17   696]\n",
    "[  130 10065]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisation point @ 7_\n",
    "Accuracy of conservative Random Forest  0.8423175650898423\n",
    "\n",
    "Sensitivity = 0.9872803708095289\n",
    "Specificity = 0.04595879556259905\n",
    "\n",
    "[  29 1602]\n",
    "[ 118 9159]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisatin point @ 6\n",
    "Accuracy of conservative Random Forest  0.7326732673267327\n",
    "\n",
    "Sensitivity = 0.9873276183376817\n",
    "Specificity = 0.015739769150052464\n",
    "\n",
    "[  45 2814]\n",
    "[ 102 7947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-494-e34a0a8b260f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSpecificity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TP' is not defined"
     ]
    }
   ],
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Sensitivity = TP / (TP + FN)\n",
    "Specificity = TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9873276183376817\n",
      "0.015739769150052464\n"
     ]
    }
   ],
   "source": [
    "def sensitivity(TP, FN):\n",
    "    return (TP / (TP + FN))\n",
    "\n",
    "def specificity (TN, FP):\n",
    "    return (TN / (TN + FP))\n",
    "\n",
    "print(sensitivity(tp,fn))\n",
    "print(specificity( tn,fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
